---
description: "Long-term memory and archival strategies for user profiles and cross-session context"
alwaysApply: false
---

## Mandate

All agentic systems **MUST** implement long-term memory and archival strategies to maintain user context across sessions. Short-term memory (current conversation messages) is insufficient for personalized, context-aware interactions. Agents must store and retrieve user insights, preferences, and patterns from a separate archival system without overloading the context window.

## 1. Long-Term Memory Architecture

### Separate Vector Database

* **Mandate:** Long-term memory must be stored in a separate Vector Database (Vector DB), not in the conversation context.

* **Architecture Pattern:**
  * **Short-term Memory:** Current conversation messages in LangGraph state
  * **Long-term Memory:** User profiles, insights, preferences in Vector DB
  * **Retrieval:** Semantic search to load relevant memories into context when needed

* **Storage Separation:** Long-term memory must be:
  * Session-independent (persists across conversations)
  * User-specific (isolated per user/tenant)
  * Searchable (semantic search capabilities)
  * Versioned (track changes over time)

**See:** `@examples_memory_storage.py` for Vector DB integration and user profile storage patterns.

### Memory Types

* **User Profile Memory:**
  * User preferences and settings
  * Communication style and tone preferences
  * Domain expertise and interests
  * Historical interaction patterns

* **Contextual Insights:**
  * Important facts mentioned in past conversations
  * User goals and objectives
  * Constraints and limitations
  * Success patterns and failures

* **Behavioral Patterns:**
  * Common request types
  * Preferred response formats
  * Interaction frequency and timing
  * Tool usage patterns

## 2. Memory Update Strategies

### When to Update

* **Post-Session Updates:**
  * Update memory after each conversation session ends
  * Extract key insights and preferences from the conversation
  * Update user profile with new information
  * Store important facts and patterns

* **Incremental Updates:**
  * Update memory during conversation when significant insights emerge
  * Real-time updates for critical information (e.g., user preferences)
  * Batch updates for non-critical information

* **Event-Driven Updates:**
  * Update memory when specific events occur (e.g., user confirms preference)
  * Trigger updates based on conversation milestones
  * Update on explicit user feedback

**See:** `@examples_memory_updates.py` for update strategies, incremental updates, and event-driven patterns.

### What to Store

* **Extraction Criteria:**
  * Store information that is:
    * User-specific (preferences, constraints, goals)
    * Persistent (unlikely to change frequently)
    * Actionable (useful for future interactions)
    * Non-sensitive (respecting privacy requirements)

* **Storage Format:**
  * Structured data (JSON) for user profiles
  * Embeddings for semantic search
  * Metadata (timestamp, source, confidence)
  * Relationships (links between related memories)

* **Avoid Storing:**
  * Temporary information (current task state)
  * Sensitive data (without proper consent)
  * Redundant information (already stored)
  * Context-specific details (belong in short-term memory)

## 3. Memory Retrieval Patterns

### Relevance-Based Retrieval

* **Semantic Search:** Use vector similarity search to find relevant memories based on current context.

* **Retrieval Triggers:**
  * At conversation start (load user profile)
  * When context is needed (on-demand retrieval)
  * When user mentions past topics (triggered retrieval)
  * Periodically during long conversations (refresh context)

* **Retrieval Strategy:**
  * Query current conversation context
  * Find top-K most relevant memories
  * Filter by recency and relevance score
  * Load into context window (with token limits)

**See:** `@examples_memory_retrieval.py` for semantic search and relevance-based retrieval patterns.

### Context Loading

* **Token-Aware Loading:**
  * Load memories within token budget
  * Prioritize most relevant memories
  * Summarize less critical memories
  * Exclude redundant information

* **Selective Loading:**
  * Load only memories relevant to current task
  * Filter by domain/topic
  * Exclude outdated information
  * Respect privacy filters

* **Loading Format:**
  * Structured summary of user profile
  * Key insights and preferences
  * Relevant historical context
  * Actionable patterns

## 4. Memory Compression and Retention

### Compression Strategies

* **Summarization:** Periodically summarize old memories to reduce storage and improve retrieval.

* **Importance Scoring:** Score memories by importance and recency to prioritize retention.

* **Deduplication:** Remove duplicate or highly similar memories.

* **Archival:** Move old, less-relevant memories to cold storage.

### Retention Policies

* **Time-Based Retention:**
  * Keep recent memories (e.g., last 90 days) in hot storage
  * Archive older memories to cold storage
  * Delete very old memories (based on policy)

* **Relevance-Based Retention:**
  * Keep frequently accessed memories
  * Keep high-importance memories
  * Archive low-relevance memories

* **User-Controlled Retention:**
  * Allow users to delete specific memories
  * Respect user privacy preferences
  * Support GDPR right to be forgotten

## 5. Privacy and Compliance

### Data Protection

* **PII Handling:**
  * Detect and mask PII in stored memories
  * Encrypt sensitive information
  * Implement access controls
  * Audit memory access

* **User Consent:**
  * Obtain consent before storing long-term memory
  * Allow users to opt-out
  * Provide memory management interface
  * Support data export and deletion

* **GDPR Compliance:**
  * Right to access stored memories
  * Right to rectification
  * Right to erasure
  * Data portability

* **See:** `security-governance-and-observability.md` for comprehensive security and privacy requirements.

## 6. Integration Points

### LangGraph Integration

* **State Management:** Long-term memory is separate from GraphState but can be loaded into state when needed.

* **Node Integration:**
  * **Load Memory Node:** Load relevant memories at conversation start
  * **Update Memory Node:** Update memory after conversation ends
  * **Retrieve Memory Node:** On-demand retrieval during conversation

* **Checkpoint Integration:** Memory updates should be persisted independently of workflow checkpoints.

### RAG Integration

* **Hybrid Search:** Combine vector search (semantic) with keyword search for memory retrieval.

* **Reranking:** Use reranking models to improve memory retrieval relevance.

* **See:** `data-schemas-and-interfaces.md` for RAG system integration patterns.

### Multi-Tenant Isolation

* **Tenant Isolation:** Each tenant must have isolated memory storage.

* **Access Control:** Enforce tenant-level access controls on memory operations.

* **Data Segregation:** Store memories in tenant-specific namespaces or databases.

## 7. Best Practices

### Memory Quality

* **Validation:** Validate extracted memories before storage.

* **Confidence Scoring:** Store confidence scores for memories to prioritize high-confidence information.

* **Source Attribution:** Track source of each memory (which conversation, which agent).

* **Versioning:** Version memories to track changes over time.

### Performance Optimization

* **Caching:** Cache frequently accessed memories in application memory.

* **Batch Operations:** Batch memory updates for efficiency.

* **Async Updates:** Perform memory updates asynchronously to avoid blocking workflow.

* **Indexing:** Maintain proper indexes for fast retrieval.

### Monitoring

* **Memory Metrics:**
  * Number of memories per user
  * Memory retrieval latency
  * Memory update frequency
  * Storage usage

* **Quality Metrics:**
  * Memory relevance scores
  * User feedback on memory accuracy
  * Memory usage effectiveness

* **See:** `monitoring-and-observability.md` for comprehensive monitoring strategies.
